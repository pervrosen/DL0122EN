{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "<a href=\"https://www.bigdatauniversity.com\"><img src=\"https://ibm.box.com/shared/static/qo20b88v1hbjztubt06609ovs85q8fau.png\" width=\"400px\" align=\"center\"></a>\n",
    "\n",
    "<br><br>\n",
    "\n",
    "<h1 align=\"center\"><font size=\"5\">Project: Character Modeling Solution Template</font></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "<h3><strong>This is a solution template, please only use the output of the cells of the questions in this notebook as a reference when grading your peer's assignment. Your the output on peer's project may differ from the output in this notebook but they might still be correct as long as they satisfy the criteria in the grading rubric.</strong></h3>\n",
    "<br>\n",
    "<font size=\"3\"><strong>In this notebook you will use TensorFlow to create a Recurrent Neural Network, to predict the next character in a string. You need to train your network using a CPU and using a GPU and benchmark the result to see which which device You have to write your code in empty cells in this notebook to make it complete, and then submit the notebook for peer-review.</strong></font>\n",
    "\n",
    "<h2>Table of Contents</h2>\n",
    "<ol>\n",
    "    <li><a href=\"#question_1\">Question 1: Complete the code to run it on CPU</a></li>\n",
    "    <li><a href=\"#question_2\">Question 2: Complete the code to run it on GPU</a></li>\n",
    "    <li><a href=\"#question_3\">Question 3: Compare the results</a></li>\n",
    "</ol>    \n",
    "<p></p>\n",
    "</div>\n",
    "<br>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "<a id=\"cpu_vs_gpu\"></a>\n",
    "<h2>Train your model using CPU and GPU</h2>\n",
    "We can train our model through feeding batches. You should be able to complete the following cells and submit it for review."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "<a id=\"question_1\"></a>\n",
    "<h2>Question 1: Complete the code to run it on CPU</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "button": false,
    "collapsed": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "173/3480 (epoch 0), train_loss = 2.049, time/batch = 0.049\n",
      "----------------------------------\n",
      "SAMPLE GENERATED TEXT:\n",
      "The purde aud mavr to bestly sour arontery.\n",
      "\n",
      "LICENEY:\n",
      "Sod nomy srowe apseed.\n",
      "'Tsy magr, with if hif the fon it Jot he rrolours,\n",
      "And bult the, for ath have\n",
      "----------------------------------\n",
      "347/3480 (epoch 1), train_loss = 1.840, time/batch = 0.051\n",
      "----------------------------------\n",
      "SAMPLE GENERATED TEXT:\n",
      "The all now me.\n",
      "\n",
      "BLACUSIUS:\n",
      "Why Rriof and weer, she restere cloned.\n",
      "\n",
      "KING WINks Have she is a greeand word to you but sup you, what ove reatonts.\n",
      "\n",
      "VETCURI\n",
      "----------------------------------\n",
      "521/3480 (epoch 2), train_loss = 1.734, time/batch = 0.062\n",
      "----------------------------------\n",
      "SAMPLE GENERATED TEXT:\n",
      "The mother, is promtation you k, vear on Rome to the muster.\n",
      "\n",
      "VOLKENCE:\n",
      "Of ewhen, loves for dere's deast thus appy of me.\n",
      "Conouses and forself me dost?\n",
      "\n",
      "T\n",
      "----------------------------------\n",
      "695/3480 (epoch 3), train_loss = 1.671, time/batch = 0.062\n",
      "----------------------------------\n",
      "SAMPLE GENERATED TEXT:\n",
      "The id causing to thus we world to ingor?'\n",
      "Nurse fadread.\n",
      "\n",
      "HENRY EMBO KING ROrenco the tongue love; sit, an\n",
      "that I I'll setrew me, ar were counterd, it vi\n",
      "----------------------------------\n",
      "869/3480 (epoch 4), train_loss = 1.627, time/batch = 0.053\n",
      "----------------------------------\n",
      "SAMPLE GENERATED TEXT:\n",
      "The wistors, years,\n",
      "As my naitiry all his clautth us\n",
      "it.\n",
      "\n",
      "CAPGTER:\n",
      "Sweak, gits to: by.\n",
      "\n",
      "HARTIS:\n",
      "My lord go revered to terevaule, agate pray not is arricio\n",
      "----------------------------------\n",
      "1043/3480 (epoch 5), train_loss = 1.594, time/batch = 0.053\n",
      "----------------------------------\n",
      "SAMPLE GENERATED TEXT:\n",
      "The gir, to she's wo-no muciter, tell moy, a sevent cause up usono,\n",
      "Which,\n",
      "And his new, I knings there's stroo; all strink see by cousin for them it a Cla\n",
      "----------------------------------\n",
      "1217/3480 (epoch 6), train_loss = 1.569, time/batch = 0.053\n",
      "----------------------------------\n",
      "SAMPLE GENERATED TEXT:\n",
      "The more is goods.\n",
      "Which not well fidling, I call my vileng.\n",
      "\n",
      "Second Citiles, and he ort thou noth your hone'By ports, you are clier.\n",
      "\n",
      "GREMENER:\n",
      "\n",
      "LEONTES:\n",
      "----------------------------------\n",
      "1391/3480 (epoch 7), train_loss = 1.550, time/batch = 0.052\n",
      "----------------------------------\n",
      "SAMPLE GENERATED TEXT:\n",
      "The Darity.\n",
      "Ho, be grows with him\n",
      "Isholturn, That you have chaims.\n",
      "\n",
      "KING HENRY VI:\n",
      "You should be spire; and thy fair worn lost pass, it is wild her in you\n",
      "----------------------------------\n",
      "1565/3480 (epoch 8), train_loss = 1.535, time/batch = 0.055\n",
      "----------------------------------\n",
      "SAMPLE GENERATED TEXT:\n",
      "The show, 'A will vourand Juntry.\n",
      "\n",
      "DUKE OF YORK:\n",
      "Mest by your daming ceritt, pray, sir.\n",
      "\n",
      "BENCUMI:\n",
      "So carried, where time you, herime that no:\n",
      "Thy lays:\n",
      "We\n",
      "----------------------------------\n",
      "1739/3480 (epoch 9), train_loss = 1.524, time/batch = 0.050\n",
      "----------------------------------\n",
      "SAMPLE GENERATED TEXT:\n",
      "The Marcer-Will marry: ald feat right meer use of wears.\n",
      "\n",
      "ISABELLA:\n",
      "Now found sting oath weelds and him and tenker that.\n",
      "\n",
      "NIRANWARD:\n",
      "Then you gentle\n",
      "And t\n",
      "----------------------------------\n",
      "1913/3480 (epoch 10), train_loss = 1.513, time/batch = 0.057\n",
      "----------------------------------\n",
      "SAMPLE GENERATED TEXT:\n",
      "The deaity him so againt,\n",
      "Andly 'me and more to sto restake of the groul a children; as I think, for is your graces rubult my histrnalled\n",
      "Aroly fordist th\n",
      "----------------------------------\n",
      "2087/3480 (epoch 11), train_loss = 1.504, time/batch = 0.048\n",
      "----------------------------------\n",
      "SAMPLE GENERATED TEXT:\n",
      "The with was my father's slanding?\n",
      "\n",
      "CORIOP:\n",
      "He wounds not deed.\n",
      "\n",
      "First Musicat of my poor of the\n",
      "Dedough?\n",
      "Bold make though you least quient\n",
      "To shand.\n",
      "\n",
      "Fir\n",
      "----------------------------------\n",
      "2261/3480 (epoch 12), train_loss = 1.496, time/batch = 0.054\n",
      "----------------------------------\n",
      "SAMPLE GENERATED TEXT:\n",
      "The good subs, here, here by the did in the way.\n",
      "\n",
      "Secours; here's like the lancle a lost save the fine, you was.\n",
      "\n",
      "KING HENRY VIR\n",
      "Yond get the way hunbbor \n",
      "----------------------------------\n",
      "2435/3480 (epoch 13), train_loss = 1.489, time/batch = 0.049\n",
      "----------------------------------\n",
      "SAMPLE GENERATED TEXT:\n",
      "The the others like the king that he serving well hard! a that, on our endean of't:\n",
      "From him I have prejestifirs;\n",
      "I hare home here--which fear more than c\n",
      "----------------------------------\n",
      "2609/3480 (epoch 14), train_loss = 1.482, time/batch = 0.052\n",
      "----------------------------------\n",
      "SAMPLE GENERATED TEXT:\n",
      "The lowd;\n",
      "'Tamfed the grointed.\n",
      "\n",
      "ANIENS:\n",
      "Some rial: the may, would forsast though therewirg, to lead want she and have mine;\n",
      "More so to\n",
      "For true, my chalt\n",
      "----------------------------------\n",
      "2783/3480 (epoch 15), train_loss = 1.476, time/batch = 0.053\n",
      "----------------------------------\n",
      "SAMPLE GENERATED TEXT:\n",
      "The must hop you, scrouch he speak their steal\n",
      "Speak.\n",
      "A gentak days we know in happy\n",
      "To the myselves, I am along.\n",
      "Bark you way some with itness,\n",
      "Abs in Bo\n",
      "----------------------------------\n",
      "2957/3480 (epoch 16), train_loss = 1.471, time/batch = 0.051\n",
      "----------------------------------\n",
      "SAMPLE GENERATED TEXT:\n",
      "The Edil of 'em ever!\n",
      "But known joy; and your woght-disds whether, resear 'she in you to be,\n",
      "For leavenly to a why thraw senithetuned\n",
      "You, choost off\n",
      "Adge\n",
      "----------------------------------\n",
      "3131/3480 (epoch 17), train_loss = 1.466, time/batch = 0.050\n",
      "----------------------------------\n",
      "SAMPLE GENERATED TEXT:\n",
      "The you will blood,\n",
      "Still, nay no love!\n",
      "\n",
      "GLOUCESTER:\n",
      "For he wild togkelont at hears curses sir!\n",
      "A poor'st.\n",
      "For a mode no man-as you loved weeper\n",
      "As, seake\n",
      "----------------------------------\n",
      "3305/3480 (epoch 18), train_loss = 1.462, time/batch = 0.052\n",
      "----------------------------------\n",
      "SAMPLE GENERATED TEXT:\n",
      "The am\n",
      "dimmy.\n",
      "\n",
      "PETAR:\n",
      "We save lady unger on Frriar:\n",
      "We will\n",
      "Be sulf the ears.-\n",
      "Firrits:\n",
      "A princeln:\n",
      "Ay,\n",
      "Stink bout a bance:\n",
      "My buy.\n",
      "I fortupper and a conf\n",
      "----------------------------------\n",
      "3479/3480 (epoch 19), train_loss = 1.458, time/batch = 0.048\n",
      "----------------------------------\n",
      "SAMPLE GENERATED TEXT:\n",
      "The thy way\n",
      "Is deposed thencuo, on the queener me,\n",
      "We have not puvile obinction rumise the wormsel, done'h the peace\n",
      "Our alanion,\n",
      "As kindly of stave and m\n",
      "----------------------------------\n"
     ]
    }
   ],
   "source": [
    "avg_batch_running_duration_CPU=[]\n",
    "tf.reset_default_graph()\n",
    "with tf.variable_scope(\"rnn_CPU\"):\n",
    "    model = LSTMModel(device='/cpu:0')\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for e in range(num_epochs): # num_epochs is 20 for test, but should be higher\n",
    "        sess.run(tf.assign(model.lr, learning_rate * (decay_rate ** e)))\n",
    "        ## write your code bellow to reset the batch pointer in data_loader. you can use reset_batch_pointer()\n",
    "        ##\n",
    "        ##\n",
    "\n",
    "        state = sess.run(model.initial_state) # model initialization\n",
    "        batch_running_duration_CPU = []\n",
    "        for b in range(data_loader.num_batches): #for each batch\n",
    "            start = time.time()\n",
    "            ## write your code to define your x and y. You should use next_batch() from data_loader\n",
    "            ## e.g. x,y =\n",
    "            ##\n",
    "\n",
    "            feed = {model.input_data: x, model.targets: y, model.initial_state:state}           \n",
    "            ## write your code to train the model\n",
    "            ## fe.g.: train_loss, state, _ = \n",
    "            ##\n",
    "\n",
    "            end = time.time()\n",
    "            ## write your code to store the duration of runing each batch in a list (end - start)\n",
    "            ##\n",
    "            ##\n",
    "            batch_running_duration_CPU.append( end - start)\n",
    "            \n",
    "        print(\"{}/{} (epoch {}), train_loss = {:.3f}, time/batch = {:.3f}\" \\\n",
    "                .format(e * data_loader.num_batches + b, num_epochs * data_loader.num_batches, e, train_loss, end - start))\n",
    "        avg_batch_running_duration_CPU.append(sum(batch_running_duration_CPU) / float(len(batch_running_duration_CPU)))\n",
    "        \n",
    "        # Please uncomment the following block of the code so the grader can see the sample of prediction\n",
    "        with tf.variable_scope(\"rnn_CPU\", reuse=True):\n",
    "            sample_model = LSTMModel(sample=True)\n",
    "            print ('----------------------------------')\n",
    "            print ('SAMPLE GENERATED TEXT:')\n",
    "            print (sample_model.sample(sess, data_loader.chars , data_loader.vocab, num=150, prime='The ', sampling_type=1))\n",
    "            print ('----------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "<a id=\"question_2\"></a>\n",
    "<h2>Question 2: Complete the code to run it on GPU</h2>\n",
    "Now, create the same network with GPU, and calculate the time/batch for running each batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "173/3480 (epoch 0), train_loss = 2.047, time/batch = 0.020\n",
      "----------------------------------\n",
      "SAMPLE GENERATED TEXT:\n",
      "The Dosteny, sicher and tay his lond\n",
      "My fory fr,\n",
      "Bundurk\n",
      "Yut toud htace.\n",
      "\n",
      "ELNENBUMANB:\n",
      "whigh I soskikedy thelise mads the kighind yoe sager\n",
      "Tamy on thas, \n",
      "----------------------------------\n",
      "347/3480 (epoch 1), train_loss = 1.839, time/batch = 0.019\n",
      "----------------------------------\n",
      "SAMPLE GENERATED TEXT:\n",
      "The waips!\n",
      "\n",
      "GLathy fecame'd waddy or wey, be vellon depore-s\n",
      "Whorselvent, preen.\n",
      "Yebleds, for is now live farourt:\n",
      "Sire, and woth, with Ge, wnow on the ki\n",
      "----------------------------------\n",
      "521/3480 (epoch 2), train_loss = 1.730, time/batch = 0.020\n",
      "----------------------------------\n",
      "SAMPLE GENERATED TEXT:\n",
      "The how'll me nogh be sor no I cave nath.\n",
      "\n",
      "ION A me in though.\n",
      "\n",
      "CLAYAL:\n",
      "God centy thre, wnot, I waich then for art\n",
      "What' servace shake 'tille on' gook one\n",
      "----------------------------------\n",
      "695/3480 (epoch 3), train_loss = 1.666, time/batch = 0.019\n",
      "----------------------------------\n",
      "SAMPLE GENERATED TEXT:\n",
      "The till the foo.\n",
      "\n",
      "LUCNIUS:\n",
      "I knath\n",
      "As in vinatsed, to us him: Gook'd wish, shepice we misting nome, the'ch in firs.\n",
      "\n",
      "ROMEO:\n",
      "Suin, I have dise of it.\n",
      "Will\n",
      "----------------------------------\n",
      "869/3480 (epoch 4), train_loss = 1.626, time/batch = 0.018\n",
      "----------------------------------\n",
      "SAMPLE GENERATED TEXT:\n",
      "The out you\n",
      "good, 'ly a nevout's thous. She have tibll our: ruad;\n",
      "Not, Blastiny of you: sir?\n",
      "'ly on, but I will long content me?\n",
      "\n",
      "Ajedy-dlawin no genter,\n",
      "\n",
      "----------------------------------\n",
      "1043/3480 (epoch 5), train_loss = 1.597, time/batch = 0.019\n",
      "----------------------------------\n",
      "SAMPLE GENERATED TEXT:\n",
      "The rast this death man\n",
      "set\n",
      "As his. Why sir, good thee,\n",
      "In Romear, soum's can blomer.\n",
      "\n",
      "YORK:\n",
      "But not to Lacter\n",
      "West this wirnst of the king unalar,\n",
      "I hall\n",
      "----------------------------------\n",
      "1217/3480 (epoch 6), train_loss = 1.574, time/batch = 0.019\n",
      "----------------------------------\n",
      "SAMPLE GENERATED TEXT:\n",
      "The But scoul ofe besce\n",
      "And to onour. Havood of the gellow's Burcunness osseaker despy the King ifly.\n",
      "What, way aried.\n",
      "\n",
      "HARIEL:\n",
      "Come? what is, veoms, with\n",
      "----------------------------------\n",
      "1391/3480 (epoch 7), train_loss = 1.556, time/batch = 0.020\n",
      "----------------------------------\n",
      "SAMPLE GENERATED TEXT:\n",
      "The state; therein, and stamp to Hanch or that\n",
      "hand matter, sir, muda,\n",
      "Her a gruesed:\n",
      "If monest, you puriest mvecerge mintaring, tell me tousin, he lemine\n",
      "----------------------------------\n",
      "1565/3480 (epoch 8), train_loss = 1.540, time/batch = 0.019\n",
      "----------------------------------\n",
      "SAMPLE GENERATED TEXT:\n",
      "The sumsunever eness let a toranced brings Edwhat be we first hours or say in As well seasing your broop and seed now to Romeans clourmench, a runt, sie: \n",
      "----------------------------------\n",
      "1739/3480 (epoch 9), train_loss = 1.527, time/batch = 0.021\n",
      "----------------------------------\n",
      "SAMPLE GENERATED TEXT:\n",
      "The woun's youns welcome brovers?\n",
      "\n",
      "BAPTISTA:\n",
      "Nor I,\n",
      "Thou scorckiling\n",
      "Bettiment a more instrum.\n",
      "\n",
      "LORNOLICD:\n",
      "O, Sif thou do banes, know them all\n",
      "allow,\n",
      "True\n",
      "----------------------------------\n",
      "1913/3480 (epoch 10), train_loss = 1.515, time/batch = 0.019\n",
      "----------------------------------\n",
      "SAMPLE GENERATED TEXT:\n",
      "The foul king.\n",
      "\n",
      "Second Senven cloudied here.\n",
      "\n",
      "First kill service, moders:\n",
      "We spake men\n",
      "Or and old in a master, I down high my deap your true which Comin b\n",
      "----------------------------------\n",
      "2087/3480 (epoch 11), train_loss = 1.504, time/batch = 0.018\n",
      "----------------------------------\n",
      "SAMPLE GENERATED TEXT:\n",
      "The does do were inquite sancame, many; that when furn presents in this subred been hime of eight with burther, my come. Thou, cheeg shomes prival,'s fort\n",
      "----------------------------------\n",
      "2261/3480 (epoch 12), train_loss = 1.494, time/batch = 0.019\n",
      "----------------------------------\n",
      "SAMPLE GENERATED TEXT:\n",
      "The beer without some shout? Great what chard may we that where, estrain our feat strived feitiness\n",
      "usscient sight to your knevismonged unyour\n",
      "with corest\n",
      "----------------------------------\n",
      "2435/3480 (epoch 13), train_loss = 1.486, time/batch = 0.020\n",
      "----------------------------------\n",
      "SAMPLE GENERATED TEXT:\n",
      "The good let in: 'Speak a gentleman: what had arw to suffer,\n",
      "How murder. Sil, gaunt eareny mind\n",
      "cred for the that you didimine take slay-dispity honesance\n",
      "----------------------------------\n",
      "2609/3480 (epoch 14), train_loss = 1.479, time/batch = 0.022\n",
      "----------------------------------\n",
      "SAMPLE GENERATED TEXT:\n",
      "The lobet. Prove not heir name,\n",
      "Have whose ye nome which commurded\n",
      "the hazens are Comuded joy. The will should subuty.\n",
      "\n",
      "ROMEO: Boy-tlay.\n",
      "\n",
      "RATCLLORDZAR:\n",
      "O,\n",
      "----------------------------------\n",
      "2783/3480 (epoch 15), train_loss = 1.473, time/batch = 0.021\n",
      "----------------------------------\n",
      "SAMPLE GENERATED TEXT:\n",
      "The from this Parish slaxt raba druming state.\n",
      "\n",
      "EONZALO:\n",
      "In, How fave hard\n",
      "being hare Margest the chursel.\n",
      "\n",
      "LADY CAPULET:\n",
      "Why lords the guld his King the \n",
      "----------------------------------\n",
      "2957/3480 (epoch 16), train_loss = 1.468, time/batch = 0.019\n",
      "----------------------------------\n",
      "SAMPLE GENERATED TEXT:\n",
      "The wounded her,\n",
      "Scit be\n",
      "Consure the breath: and bright too noil't a grave to essent now, was vilen answer and paice order-sonk and jeture.\n",
      "\n",
      "Third Murded \n",
      "----------------------------------\n",
      "3131/3480 (epoch 17), train_loss = 1.463, time/batch = 0.019\n",
      "----------------------------------\n",
      "SAMPLE GENERATED TEXT:\n",
      "The I now\n",
      "Your nareful wedded rived: he's hand fore sir, you sif, why which yet, my lord.\n",
      "\n",
      "ESCALUS:\n",
      "And strangs a satings along!\n",
      "\n",
      "CORIOLANUS:\n",
      "I will woo\n",
      "H\n",
      "----------------------------------\n",
      "3305/3480 (epoch 18), train_loss = 1.459, time/batch = 0.022\n",
      "----------------------------------\n",
      "SAMPLE GENERATED TEXT:\n",
      "The roney acred time how!\n",
      "When in us both thee;\n",
      "BO, sir! hence should you speak?\n",
      "\n",
      "ShestRO:\n",
      "A filth here.\n",
      "And before's forbidfect.\n",
      "\n",
      "Ghost the worded.\n",
      "\n",
      "HORT\n",
      "----------------------------------\n",
      "3479/3480 (epoch 19), train_loss = 1.455, time/batch = 0.019\n",
      "----------------------------------\n",
      "SAMPLE GENERATED TEXT:\n",
      "The phead of me\n",
      "morserbior cans,\n",
      "He puck! God thou all, Godry fooling I might these winder.\n",
      "\n",
      "ISABELLA:\n",
      "But, thou loves: I will I will subbly.;\n",
      "Elvier her \n",
      "----------------------------------\n"
     ]
    }
   ],
   "source": [
    "avg_batch_running_duration_GPU=[]\n",
    "tf.reset_default_graph()\n",
    "with tf.variable_scope(\"rnn_GPU\"):\n",
    "    model = LSTMModel(device='/gpu:0')\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for e in range(num_epochs): # num_epochs is 20 for test, but should be higher\n",
    "        sess.run(tf.assign(model.lr, learning_rate * (decay_rate ** e)))\n",
    "        ## write your code bellow to reset the batch pointer in data_loader. you can use reset_batch_pointer()\n",
    "        ##\n",
    "        ##\n",
    "\n",
    "        state = sess.run(model.initial_state) # model initialization\n",
    "        batch_running_duration_GPU = []\n",
    "        for b in range(data_loader.num_batches): #for each batch\n",
    "            start = time.time()\n",
    "            ## write your code to define your x and y. You should use next_batch() from data_loader\n",
    "            ## e.g. x,y =\n",
    "            ##\n",
    "\n",
    "            feed = {model.input_data: x, model.targets: y, model.initial_state:state}\n",
    "            ## write your code to train the model\n",
    "            ## fe.g.: train_loss, state, _ = \n",
    "            ##\n",
    "\n",
    "            end = time.time()\n",
    "            ## write your code to store the duration of runing each batch in a list (end - start)\n",
    "            ##\n",
    "            ##\n",
    "            \n",
    "        print(\"{}/{} (epoch {}), train_loss = {:.3f}, time/batch = {:.3f}\" \\\n",
    "                .format(e * data_loader.num_batches + b, num_epochs * data_loader.num_batches, e, train_loss, end - start))\n",
    "        avg_batch_running_duration_GPU.append(sum(batch_running_duration_GPU) / float(len(batch_running_duration_GPU)))\n",
    "        \n",
    "        # Please uncomment the following block of the code so the grader can see the sample of prediction\n",
    "        with tf.variable_scope(\"rnn_GPU\", reuse=True):\n",
    "            sample_model = LSTMModel(sample=True)\n",
    "            print ('----------------------------------')\n",
    "            print ('SAMPLE GENERATED TEXT:')\n",
    "            print (sample_model.sample(sess, data_loader.chars , data_loader.vocab, num=150, prime='The ', sampling_type=1))\n",
    "            print ('----------------------------------')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "<a id=\"question_3\"></a>\n",
    "<h2>Question 3: Compare the results</h2>\n",
    "Finally, using a graph, show the speed of training (batch/time) for the model running on GPU and CPU:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Write your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "<h2>Do you want to use GPU in production?</h2>\n",
    "\n",
    "<p>Running deep learning programs usually needs a high performance platform. PowerAI speeds up deep learning and AI. Built on IBM's Power Systems, PowerAI is a scalable software platform that accelerates deep learning and AI with blazing performance for individual users or enterprises. The <a href=\"https://cocl.us/ML0122EN_IBMCLOUD_PowerAI\">PowerAI platform on IBM Cloud</a> supports popular machine learning libraries and dependencies including TensorFlow, Caffe, PyTorch, and Theano.</p>\n",
    "\n",
    "<h3>Thanks for completing this lesson!</h3>\n",
    "\n",
    "\n",
    "\n",
    "<h4>Author:  <a href=\"https://ca.linkedin.com/in/saeedaghabozorgi\">Saeed Aghabozorgi</a>,   <a href=\"https://www.linkedin.com/in/yi-leng-yao-84451275/\">Yi leng Yao</a></h4>\n",
    "<p><a href=\"https://ca.linkedin.com/in/saeedaghabozorgi\">Saeed Aghabozorgi</a>, PhD is a Data Scientist in IBM with a track record of developing enterprise level applications that substantially increases clientsâ€™ ability to turn data into actionable knowledge. He is a researcher in data mining field and expert in developing advanced analytic methods like machine learning and statistical modelling on large datasets.</p>\n",
    "</article>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "<hr>\n",
    "\n",
    "<p>Copyright &copy; 2018 <a href=\"https://cocl.us/DX0108EN_CC\">Cognitive Class</a>. This notebook and its source code are released under the terms of the <a href=\"https://bigdatauniversity.com/mit-license/\">MIT License</a>.</p>"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
